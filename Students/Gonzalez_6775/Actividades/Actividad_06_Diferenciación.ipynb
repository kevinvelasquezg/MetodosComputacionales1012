{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZuc8vXcWuxy"
      },
      "outputs": [],
      "source": [
        "#@title Librerias\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sympy as sp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actividad 06: Diferenciación númerica\n",
        "\n",
        "---\n",
        "### Profesor: Juan Marcos Marín\n",
        "### Nombre: Kevin Velasquez Gonzalez\n",
        "---"
      ],
      "metadata": {
        "id": "MGwGfceuWxy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.\n",
        "Implementar el método de la derivada de cinco puntos a través de una función llamada `five_point_derivative`. Luego,\n",
        "* Calcule el valor para $f(x) = \\cos(x)$ utilizando un arreglo con 10 datos $[0\\leq x\\leq 2\\pi]$ y encuentre $f'(\\pi/8)$ variando el $h$ y encuentre el error de convergencia, comparando su respuesta con el valor exacto.\n",
        "\n",
        "* Determine $f''(\\pi/8)$ con $h = 0.05$ y encuentre el error de su aproximación. ¿Mejorará con un $h$ menor o mayor?\n",
        "\n"
      ],
      "metadata": {
        "id": "E8ME9Aa7TbKA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyTohkly7IW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b4a958-639d-41f2-ffb7-f16a97b9b5fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h = 0.5, derivada = -0.3819095602367959, error = 0.0007738721282938843\n",
            "h = 0.25, derivada = -0.38263397319288756, error = 4.94591722022264e-05\n",
            "h = 0.1, derivada = -0.3826821582713475, error = 1.2740937422872634e-06\n",
            "h = 0.05, derivada = -0.38268335266309955, error = 7.970199022988567e-08\n",
            "h = 0.01, derivada = -0.3826834322375313, error = 1.2755846379164382e-10\n",
            "\n",
            "Segunda derivada con h = 0.05\n",
            "Valor aproximado: -0.9238794683673055\n",
            "Error: 6.414398123766318e-08\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def f(x):\n",
        "    return np.cos(x)\n",
        "\n",
        "def five_point_derivative(f, x, h):\n",
        "    return (-f(x + 2*h) + 8*f(x + h) - 8*f(x - h) + f(x - 2*h)) / (12*h)\n",
        "\n",
        "x = np.linspace(0, 2*np.pi, 10)\n",
        "punto = np.pi / 8\n",
        "valor_real = -np.sin(punto)\n",
        "\n",
        "h_values = [0.5, 0.25, 0.1, 0.05, 0.01]\n",
        "errores = []\n",
        "\n",
        "for h in h_values:\n",
        "    aprox = five_point_derivative(f, punto, h)\n",
        "    error = abs(aprox - valor_real)\n",
        "    errores.append(error)\n",
        "    print(f\"h = {h}, derivada = {aprox}, error = {error}\")\n",
        "\n",
        "def second_derivative(f, x, h):\n",
        "    return (-f(x + 2*h) + 16*f(x + h) - 30*f(x) + 16*f(x - h) - f(x - 2*h)) / (12*h**2)\n",
        "\n",
        "h = 0.05\n",
        "aprox2 = second_derivative(f, punto, h)\n",
        "valor_real2 = -np.cos(punto)\n",
        "error2 = abs(aprox2 - valor_real2)\n",
        "\n",
        "print(f\"\\nSegunda derivada con h = {h}\")\n",
        "print(f\"Valor aproximado: {aprox2}\")\n",
        "print(f\"Error: {error2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.\n",
        "Considere la función:\n",
        "\n",
        "$$f(x) = x e^x$$\n",
        "\n",
        "Encuentre la derivada númerica $f'(x)$ y $f''(x)$ para $x = 2.0$ usando diferencias finitas. Considere un arreglo con 6 puntos $[1.8\\leq x\\leq 2.2]$.\n",
        "\n",
        "*   Cambie los valores de $h$ desde 0.01 hasta 0.1 (tomando 10 diferentes) y compare su resultado con el dado por `scipy` y `numpy.gradient`. Realice un gráfico logaritmico de los errores.\n",
        "\n",
        "*   ¿Cuál será el valor óptimo de $h$?"
      ],
      "metadata": {
        "id": "Dx40CzPL-V8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import BarycentricInterpolator\n",
        "\n",
        "# Función\n",
        "def f(x):\n",
        "    return x * np.exp(x)\n",
        "\n",
        "# Punto donde queremos la derivada\n",
        "x0 = 2.0\n",
        "\n",
        "# Valores de h\n",
        "h_vals = np.linspace(0.01, 0.1, 10)\n",
        "\n",
        "# Guardar errores\n",
        "errores_fd1 = []\n",
        "errores_fd2 = []\n",
        "errores_scipy = []\n",
        "errores_grad = []\n",
        "\n",
        "# Derivada exacta de f(x) = x·e^x => f'(x) = e^x(x+1), f''(x) = e^x(x+2)\n",
        "f1_real = np.exp(x0) * (x0 + 1)\n",
        "f2_real = np.exp(x0) * (x0 + 2)\n",
        "\n",
        "for h in h_vals:\n",
        "    # Diferencias finitas centradas\n",
        "    f1_aprox = (f(x0 + h) - f(x0 - h)) / (2*h)\n",
        "    f2_aprox = (f(x0 + h) - 2*f(x0) + f(x0 - h)) / (h**2)\n",
        "\n",
        "    # Scipy: Interpolación con 6 puntos en [1.8, 2.2]\n",
        "    x_vals = np.linspace(1.8, 2.2, 6)\n",
        "    y_vals = f(x_vals)\n",
        "    interp = BarycentricInterpolator(x_vals, y_vals)\n",
        "\n",
        "    f1_scipy = interp.derivative(1)(x0)\n",
        "    f2_scipy = interp.derivative(2)(x0)\n",
        "\n",
        "    # Gradient de numpy con 3 puntos [x0-h, x0, x0+h]\n",
        "    x_arr = np.array([x0 - h, x0, x0 + h])\n",
        "    y_arr = f(x_arr)\n",
        "    grad = np.gradient(y_arr, h)\n",
        "    f1_grad = grad[1]\n",
        "\n",
        "    # Guardar errores\n",
        "    errores_fd1.append(abs(f1_aprox - f1_real))\n",
        "    errores_fd2.append(abs(f2_aprox - f2_real))\n",
        "    errores_scipy.append(abs(f1_scipy - f1_real))\n",
        "    errores_grad.append(abs(f1_grad - f1_real))\n",
        "\n",
        "# Gráfico\n",
        "plt.plot(h_vals, errores_fd1, label=\"Error f'(x) finitas\")\n",
        "plt.plot(h_vals, errores_fd2, label=\"Error f''(x) finitas\")\n",
        "plt.plot(h_vals, errores_scipy, label=\"Error f'(x) scipy\")\n",
        "plt.plot(h_vals, errores_grad, label=\"Error f'(x) gradient\")\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"h\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.title(\"Errores de derivación vs h (escala log)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Aar3rT02CSel"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}